{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4HYPwkb6deW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import dask.dataframe as dd\n",
        "import pexpect\n",
        "import html\n",
        "import re\n",
        "from IPython.display import display\n",
        "import json\n",
        "from matplotlib import pyplot as plt\n",
        "import ast\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import ast\n",
        "from google.colab.drive import mount\n",
        "import pickle\n",
        "import urllib.request\n",
        "import os\n",
        "import gzip\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TTmXlw6ehJh",
        "outputId": "e9db1cc8-ed81-4ccb-f3f2-e08ba7ee7364"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m827.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MebhE890Blse",
        "outputId": "8906fc63-d0b4-4cc7-f85a-41f2d50af713"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at ./data; to attempt to forcibly remount, call drive.mount(\"./data\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "mount('./data')\n",
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json('./cellphones_review.jsonl', lines=True, nrows=10)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "L_NMIYdHjRXs",
        "outputId": "2ded09c7-525f-4140-91c6-e8cde1cf0bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   overall  verified   reviewTime      reviewerID        asin  \\\n",
              "0        5      True   08 4, 2014  A24E3SXTC62LJI  7508492919   \n",
              "1        5      True  02 12, 2014  A269FLZCB4GIPV  7508492919   \n",
              "2        3      True   02 8, 2014   AB6CHQWHZW4TV  7508492919   \n",
              "3        2      True   02 4, 2014   A1M117A53LEI8  7508492919   \n",
              "4        4      True   02 3, 2014  A272DUT8M88ZS8  7508492919   \n",
              "5        2      True  01 27, 2014  A1DW2L6XCC5TJS  7508492919   \n",
              "6        3      True  01 23, 2014   AQC61R4UST7UH  7508492919   \n",
              "7        5      True  01 17, 2014  A31OVFL91BCKXG  7508492919   \n",
              "8        1      True  12 27, 2013  A1K0VLK6O5Z22M  7508492919   \n",
              "9        4      True  12 16, 2013  A1K3BWU73YB44P  7508492919   \n",
              "\n",
              "                  style          reviewerName  \\\n",
              "0  {'Color:': ' Bling'}      Claudia Valdivia   \n",
              "1                   NaN           sarah ponce   \n",
              "2                   NaN                   Kai   \n",
              "3                   NaN       Sharon Williams   \n",
              "4                   NaN       Bella Rodriguez   \n",
              "5                   NaN       Amazon Customer   \n",
              "6                   NaN          DaMara Estep   \n",
              "7                   NaN  Ashley Nicole Miller   \n",
              "8                   NaN             BeeLove21   \n",
              "9                   NaN            Mrs. Ochoa   \n",
              "\n",
              "                                          reviewText  \\\n",
              "0  Looks even better in person. Be careful to not...   \n",
              "1  When you don't want to spend a whole lot of ca...   \n",
              "2  so the case came on time, i love the design. I...   \n",
              "3  DON'T CARE FOR IT.  GAVE IT AS A GIFT AND THEY...   \n",
              "4  I liked it because it was cute, but the studs ...   \n",
              "5  The product looked exactly like the picture an...   \n",
              "6  I FINALLY got my case today. It took forever t...   \n",
              "7  It is a very cute case. None of the jewels hav...   \n",
              "8  DO NOT BUY! this item is seriously cheap as he...   \n",
              "9  I really love this case... you have to keep yo...   \n",
              "\n",
              "                               summary  unixReviewTime  \n",
              "0  Can't stop won't stop looking at it      1407110400  \n",
              "1                                    1      1392163200  \n",
              "2                             Its okay      1391817600  \n",
              "3                                 CASE      1391472000  \n",
              "4                                Cute!      1391385600  \n",
              "5                         Not so happy      1390780800  \n",
              "6                           It's cute!      1390435200  \n",
              "7                            Cute case      1389916800  \n",
              "8                          WORST ITEM!      1388102400  \n",
              "9                         Pretty Cute!      1387152000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9094cf90-50c5-4170-a62c-46b66f788c45\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>verified</th>\n",
              "      <th>reviewTime</th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>style</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>08 4, 2014</td>\n",
              "      <td>A24E3SXTC62LJI</td>\n",
              "      <td>7508492919</td>\n",
              "      <td>{'Color:': ' Bling'}</td>\n",
              "      <td>Claudia Valdivia</td>\n",
              "      <td>Looks even better in person. Be careful to not...</td>\n",
              "      <td>Can't stop won't stop looking at it</td>\n",
              "      <td>1407110400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>02 12, 2014</td>\n",
              "      <td>A269FLZCB4GIPV</td>\n",
              "      <td>7508492919</td>\n",
              "      <td>NaN</td>\n",
              "      <td>sarah ponce</td>\n",
              "      <td>When you don't want to spend a whole lot of ca...</td>\n",
              "      <td>1</td>\n",
              "      <td>1392163200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>02 8, 2014</td>\n",
              "      <td>AB6CHQWHZW4TV</td>\n",
              "      <td>7508492919</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Kai</td>\n",
              "      <td>so the case came on time, i love the design. I...</td>\n",
              "      <td>Its okay</td>\n",
              "      <td>1391817600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>02 4, 2014</td>\n",
              "      <td>A1M117A53LEI8</td>\n",
              "      <td>7508492919</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sharon Williams</td>\n",
              "      <td>DON'T CARE FOR IT.  GAVE IT AS A GIFT AND THEY...</td>\n",
              "      <td>CASE</td>\n",
              "      <td>1391472000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "      <td>02 3, 2014</td>\n",
              "      <td>A272DUT8M88ZS8</td>\n",
              "      <td>7508492919</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Bella Rodriguez</td>\n",
              "      <td>I liked it because it was cute, but the studs ...</td>\n",
              "      <td>Cute!</td>\n",
              "      <td>1391385600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>01 27, 2014</td>\n",
              "      <td>A1DW2L6XCC5TJS</td>\n",
              "      <td>7508492919</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Amazon Customer</td>\n",
              "      <td>The product looked exactly like the picture an...</td>\n",
              "      <td>Not so happy</td>\n",
              "      <td>1390780800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>01 23, 2014</td>\n",
              "      <td>AQC61R4UST7UH</td>\n",
              "      <td>7508492919</td>\n",
              "      <td>NaN</td>\n",
              "      <td>DaMara Estep</td>\n",
              "      <td>I FINALLY got my case today. It took forever t...</td>\n",
              "      <td>It's cute!</td>\n",
              "      <td>1390435200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>01 17, 2014</td>\n",
              "      <td>A31OVFL91BCKXG</td>\n",
              "      <td>7508492919</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ashley Nicole Miller</td>\n",
              "      <td>It is a very cute case. None of the jewels hav...</td>\n",
              "      <td>Cute case</td>\n",
              "      <td>1389916800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>12 27, 2013</td>\n",
              "      <td>A1K0VLK6O5Z22M</td>\n",
              "      <td>7508492919</td>\n",
              "      <td>NaN</td>\n",
              "      <td>BeeLove21</td>\n",
              "      <td>DO NOT BUY! this item is seriously cheap as he...</td>\n",
              "      <td>WORST ITEM!</td>\n",
              "      <td>1388102400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "      <td>12 16, 2013</td>\n",
              "      <td>A1K3BWU73YB44P</td>\n",
              "      <td>7508492919</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mrs. Ochoa</td>\n",
              "      <td>I really love this case... you have to keep yo...</td>\n",
              "      <td>Pretty Cute!</td>\n",
              "      <td>1387152000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9094cf90-50c5-4170-a62c-46b66f788c45')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9094cf90-50c5-4170-a62c-46b66f788c45 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9094cf90-50c5-4170-a62c-46b66f788c45');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-aaf46b68-4df7-4660-a9ad-6fac8d761386\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aaf46b68-4df7-4660-a9ad-6fac8d761386')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-aaf46b68-4df7-4660-a9ad-6fac8d761386 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_eb3eff9e-118a-4420-b1a6-d75e920b76d7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_eb3eff9e-118a-4420-b1a6-d75e920b76d7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"overall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"verified\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reviewTime\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"12 27, 2013\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reviewerID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"A1K0VLK6O5Z22M\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"asin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 7508492919,\n        \"max\": 7508492919,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          7508492919\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"style\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reviewerName\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"BeeLove21\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reviewText\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"DO NOT BUY! this item is seriously cheap as heck. not worth buying it at all. I didn't even get to use it and it was already losing all of its gems. I wish I got my money back on this item!!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"WORST ITEM!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unixReviewTime\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5537731,\n        \"min\": 1387152000,\n        \"max\": 1407110400,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1388102400\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[5].description"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pEePMFKqsCq",
        "outputId": "4d380492-6e5f-47c7-90ce-0f83ee3cde7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A brand-new, unused, unopened, undamaged item in its original packaging (where packaging is applicable).']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  ID of the reviewer, e.g. A2SUAM1J3GNN3B\n",
        "  ID of the product, e.g. 0000013714\n",
        "  name of the reviewer\n",
        "  helpful votes of the review\n",
        "  a disctionary of the product metadata, e.g., \"Format\" is \"Hardcover\"\n",
        "  text of the review\n",
        "  rating of the product\n",
        "  summary of the review\n",
        "  time of the review (unix time)\n",
        "  time of the review (raw)\n",
        "  images that users post after they have received the product"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3Q-9GvIo4uK",
        "outputId": "5b08e643-8add-4bb9-f86c-4597b1e33cd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['also_buy', 'also_view', 'asin', 'brand', 'category', 'date',\n",
              "       'description', 'details', 'feature', 'fit', 'imageURL',\n",
              "       'imageURLHighRes', 'main_cat', 'price', 'rank', 'similar_item', 'tech1',\n",
              "       'tech2', 'title'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM4ealEYBBbV"
      },
      "source": [
        "## Configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ao3hm9xNBAoO"
      },
      "outputs": [],
      "source": [
        "class PathConfig:\n",
        "\n",
        "  def __init__(self, drive_dataset_path, pickle_save_path):\n",
        "    self.DRIVE_DATASET_PATH = drive_dataset_path\n",
        "    self.PICKLE_SAVE_PATH = pickle_save_path\n",
        "    if not os.path.exists(pickle_save_path):\n",
        "      os.mkdir(pickle_save_path)\n",
        "\n",
        "  DRIVE_DATASET_PATH = \"/content/data/MyDrive/Research/dataset\"\n",
        "  PICKLE_SAVE_PATH = \"/content/data/MyDrive/Research/dataset/parquets\"\n",
        "\n",
        "  # preprocess paths\n",
        "  TMP_UIDS_PATH = './tmp_uid.parquet'\n",
        "  TMP_ITEMS_PATH = './tmp_itemid.parquet'\n",
        "\n",
        "  paths = {\n",
        "      'UID_MAP_PATH': 'uid_map.parquet',\n",
        "      'ITEMID_MAP_PATH': './itemid_map.parquet',\n",
        "      'RELATIONS_MAP_PATH': './relations_map.parquet',\n",
        "      'TAGS_MAPPING_PATH': './tags_map.parquet',\n",
        "      'BRANDS_MAPPING_PATH': './brands_map.parquet',\n",
        "      'CATEGORY_MAPPING_PATH': './category_map.parquet',\n",
        "      'CATEGORY_HIERARCHY_PATH': './category_hierarchy.parquet',\n",
        "      'ITEMMETA_PARQUET_PATH': './itemmeta.parquet',\n",
        "      'REVIEW_PARQUET_PATH': './review.parquet',\n",
        "      'USER_EMBEDDINGS_PATH': './userembeddings.parquet',\n",
        "      'ITEM_EMBEDDIGNS_PATH': './itemembeddings.parquet',\n",
        "      'TRIPLES_ITEMCAT_PATH': './triples_itemcat.parquet',\n",
        "      'TRIPLES_BRANDS_PATH': './triples_brand.parquet',\n",
        "      'TRIPLES_TAGS_PATH': './triples_tags.parquet',\n",
        "\n",
        "\n",
        "      'INDEXER_DATA_PATH': './indexer_path.pickle',\n",
        "      'TFIDF_MODEL_PATH': './tfidf.pickle'\n",
        "  }\n",
        "\n",
        "  @property\n",
        "  def UID_MAP_PATH(self):\n",
        "    return self.paths['UID_MAP_PATH']\n",
        "\n",
        "  @property\n",
        "  def ITEMID_MAP_PATH(self):\n",
        "    return self.paths['ITEMID_MAP_PATH']\n",
        "\n",
        "  @property\n",
        "  def RELATIONS_MAP_PATH(self):\n",
        "    return self.paths['RELATIONS_MAP_PATH']\n",
        "\n",
        "  @property\n",
        "  def TAGS_MAPPING_PATH(self):\n",
        "    return self.paths['TAGS_MAPPING_PATH']\n",
        "\n",
        "  @property\n",
        "  def ITEMMETA_PARQUET_PATH(self):\n",
        "    return self.paths['ITEMMETA_PARQUET_PATH']\n",
        "\n",
        "  @property\n",
        "  def REVIEW_PARQUET_PATH(self):\n",
        "    return self.paths['REVIEW_PARQUET_PATH']\n",
        "\n",
        "  @property\n",
        "  def BRANDS_MAPPING_PATH(self):\n",
        "    return self.paths['BRANDS_MAPPING_PATH']\n",
        "\n",
        "  @property\n",
        "  def CATEGORY_MAPPING_PATH(self):\n",
        "    return self.paths['CATEGORY_MAPPING_PATH']\n",
        "\n",
        "  @property\n",
        "  def CATEGORY_HIERARCHY_PATH(self):\n",
        "    return self.paths['CATEGORY_HIERARCHY_PATH']\n",
        "\n",
        "  @property\n",
        "  def USER_EMBEDDINGS_PATH(self):\n",
        "    return self.paths['USER_EMBEDDINGS_PATH']\n",
        "\n",
        "  @property\n",
        "  def ITEM_EMBEDDIGNS_PATH(self):\n",
        "    return self.paths['ITEM_EMBEDDIGNS_PATH']\n",
        "\n",
        "  @property\n",
        "  def TRIPLES_ITEMCAT_PATH(self):\n",
        "    return self.paths['TRIPLES_ITEMCAT_PATH']\n",
        "\n",
        "  @property\n",
        "  def TRIPLES_BRANDS_PATH(self):\n",
        "    return self.paths['TRIPLES_BRANDS_PATH']\n",
        "\n",
        "  @property\n",
        "  def TRIPLES_TAGS_PATH(self):\n",
        "    return self.paths['TRIPLES_TAGS_PATH']\n",
        "\n",
        "  @property\n",
        "  def TFIDF_MODEL_PATH(self):\n",
        "    return self.paths['TFIDF_MODEL_PATH']\n",
        "\n",
        "  @property\n",
        "  def INDEXER_DATA_PATH(self):\n",
        "    return self.paths['INDEXER_DATA_PATH']\n",
        "\n",
        "  def copy_to_drive(self):\n",
        "    self.use_local_paths()\n",
        "    for path in self.paths:\n",
        "      if os.path.exists(self.paths[path]):\n",
        "        print('copy_to_drive: copying ', self.paths[path])\n",
        "        shutil.copy(self.paths[path], os.path.join(self.DRIVE_DATASET_PATH, 'parquets'))\n",
        "\n",
        "  def copy_to_local(self):\n",
        "    self.use_drive_paths()\n",
        "    for path in self.paths:\n",
        "      if os.path.exists(self.paths[path]):\n",
        "        shutil.copy(self.paths[path], './')\n",
        "    self.use_local_paths()\n",
        "\n",
        "  def use_drive_paths(self):\n",
        "    for path in self.paths:\n",
        "      self.paths[path] = os.path.join(self.DRIVE_DATASET_PATH, 'parquets', os.path.basename(self.paths[path]))\n",
        "\n",
        "  def use_local_paths(self):\n",
        "    for path in self.paths:\n",
        "      self.paths[path] = './'+os.path.basename(self.paths[path])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msPHQ3T_MLwL"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "  paths = PathConfig(\"/content/data/MyDrive/Research/dataset\", \"/content/data/MyDrive/Research/dataset/parquets\")\n",
        "  use_newdata = False\n",
        "  use_bigdata = True\n",
        "  use_parquets = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keLEee0GRyNq"
      },
      "outputs": [],
      "source": [
        "config = Config()\n",
        "\n",
        "review_file = 'review.jsonl'\n",
        "meta_file = 'meta.jsonl'\n",
        "\n",
        "def init():\n",
        "\n",
        "  if (not config.use_newdata) and (not config.use_bigdata) and (not config.use_parquets):\n",
        "    return\n",
        "\n",
        "  if config.use_parquets:\n",
        "    config.paths.copy_to_local()\n",
        "    return\n",
        "\n",
        "  if config.use_bigdata:\n",
        "    global review_file, meta_file\n",
        "    review_file = 'cellphones_review.jsonl'\n",
        "    meta_file = 'cellphones_meta.jsonl'\n",
        "\n",
        "  if config.use_newdata:\n",
        "    !rm ./{review_file}\n",
        "    !rm ./{meta_file}\n",
        "\n",
        "  if not os.path.exists('./' + review_file):\n",
        "    !cp {config.paths.DRIVE_DATASET_PATH}/{review_file} ./\n",
        "  if not os.path.exists('./' + meta_file):\n",
        "    !cp {config.paths.DRIVE_DATASET_PATH}/{meta_file} ./\n",
        "\n",
        "init()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm *.parquet"
      ],
      "metadata": {
        "id": "XQ3Z-It-LMUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp {config.paths.DRIVE_DATASET_PATH}/parquets/itemmeta_v1.parquet ./itemmeta.parquet"
      ],
      "metadata": {
        "id": "_TPDFEwdXRBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIX6ff6V6nVp"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeTKJbZhattp"
      },
      "source": [
        "# Dataset Pre-processing By Batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiUhBMIhwDWP"
      },
      "outputs": [],
      "source": [
        "def save_pickle(obj, filename):\n",
        "  with open(filename, 'w') as f:\n",
        "    pickle.dump(obj, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWtjpkrj7dLS"
      },
      "outputs": [],
      "source": [
        "from collections.abc import Callable\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "import os\n",
        "\n",
        "def write_parquet(outputParquetPath, df: pd.DataFrame, append=False):\n",
        "  if isinstance(df, dd.DataFrame):\n",
        "    df = df.compute()\n",
        "\n",
        "  old_data = None\n",
        "  if os.path.exists(outputParquetPath):\n",
        "    if not append:\n",
        "      os.remove(outputParquetPath)\n",
        "    else:\n",
        "      old_data = pq.read_table(outputParquetPath)\n",
        "\n",
        "  table = pa.Table.from_pandas(df)\n",
        "  if old_data:\n",
        "    table = pa.concat_tables([old_data, table])\n",
        "\n",
        "  pq.write_table(table, outputParquetPath, compression='snappy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hlUGZhMaM-Q"
      },
      "outputs": [],
      "source": [
        "title_tfidf_encoder = TfidfVectorizer(stop_words='english')\n",
        "feature_tfidf_encoder = TfidfVectorizer(stop_words='english')\n",
        "price_encoder = MinMaxScaler()\n",
        "rating_encoder = MinMaxScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRJDbOApdBE5"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def sinusoidal_transform(timestamp):\n",
        "  dt = datetime.fromtimestamp(timestamp)\n",
        "  return [\n",
        "      np.sin(2 * np.pi * dt.day/31),\n",
        "      np.cos(2 * np.pi * dt.day/31),\n",
        "      np.sin(2 * np.pi * dt.month/12),\n",
        "      np.cos(2 * np.pi * dt.month/12)\n",
        "  ]\n",
        "\n",
        "def time_encoder(ddf: dd.DataFrame) -> dd.Series:\n",
        "  ddf = ddf.assign(\n",
        "      sin_day= ddf['unixReviewTime'].apply(lambda x: sinusoidal_transform(x)[0]),\n",
        "      cos_day= ddf['unixReviewTime'].apply(lambda x: sinusoidal_transform(x)[1]),\n",
        "      sin_month = ddf['unixReviewTime'].apply(lambda x: sinusoidal_transform(x)[2]),\n",
        "      cos_month= ddf['unixReviewTime'].apply(lambda x: sinusoidal_transform(x)[3])\n",
        "  )\n",
        "  return ddf\n",
        "\n",
        "def time_decoder(ddf: dd.DataFrame) -> dd.DataFrame:\n",
        "  timestamp = (31/(2*np.pi)) * np.arctan2(ddf['sin_day'], ddf['cos_day'])\n",
        "  ddf = ddf.assign(timestamp=timestamp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPlAYkAjYdN7"
      },
      "outputs": [],
      "source": [
        "from collections.abc import Callable\n",
        "\n",
        "def batch_extract(file, extractor: Callable[[pd.DataFrame], pd.DataFrame]):\n",
        "  chunk_size = 20000\n",
        "\n",
        "  with open(file, 'r') as file:\n",
        "      batch = []\n",
        "      for i, line in enumerate(file):\n",
        "          try:\n",
        "            batch.append(json.loads(line))\n",
        "          except Exception as e:\n",
        "            print(f\"Error processing line {i}: {e}\", line)\n",
        "            continue\n",
        "\n",
        "          # batch loaded therefore processing calling extractor...\n",
        "          if (i + 1) % chunk_size == 0:\n",
        "              df = pd.DataFrame(batch)\n",
        "              ddf = dd.from_pandas(df, 2)\n",
        "              df = extractor(ddf)\n",
        "\n",
        "              print(f\"Processed batch {(i + 1) // chunk_size}\")\n",
        "              batch = []  # Clear the batch for the next chunk\n",
        "\n",
        "      # Process the last batch. if there any remaining\n",
        "      if batch:\n",
        "          df = pd.DataFrame(batch)\n",
        "          ddf = dd.from_pandas(df)\n",
        "          df = extractor(ddf)\n",
        "          print(f\"Processed final batch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gfj_4uPKVrgL"
      },
      "outputs": [],
      "source": [
        "def extract_review_features(ddf: dd.DataFrame):\n",
        "  # Following features are not used : style, reviewText, summary, image\n",
        "  ddf_final = ddf[['reviewerID', 'asin', 'overall', 'unixReviewTime']]\n",
        "  ddf_final = ddf_final.map_partitions(time_encoder, meta={\n",
        "                                    **ddf_final.dtypes,\n",
        "                                    'sin_day': 'f8',\n",
        "                                    'cos_day': 'f8',\n",
        "                                    'sin_month': 'f8',\n",
        "                                    'cos_month': 'f8',\n",
        "                                  })\n",
        "  write_parquet(config.paths.REVIEW_PARQUET_PATH, ddf_final, append=True)\n",
        "\n",
        "  return ddf_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLIKn3uuDdXb"
      },
      "outputs": [],
      "source": [
        "config.paths.copy_to_drive()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhqFqOHQWTjc"
      },
      "outputs": [],
      "source": [
        "batch_extract(review_file, extract_review_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8O2MRXBBnQgg"
      },
      "outputs": [],
      "source": [
        "def extract_itemmeta_features(ddf):\n",
        "  # we remove ['tech1', ]\n",
        "  batchDf = ddf[['asin', 'title', 'price', 'brand', 'category', 'also_buy', 'rank', 'feature']]\n",
        "  write_parquet(config.paths.ITEMMETA_PARQUET_PATH, batchDf, append=True)\n",
        "  return batchDf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T012Hh5GeQkg"
      },
      "outputs": [],
      "source": [
        "batch_extract(meta_file, extract_itemmeta_features)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fc = pd.Series([cat for row in df['category'] for cat in row], name='a').value_counts()\n",
        "fc = fc[fc > 0]\n",
        "fc[-20:]"
      ],
      "metadata": {
        "id": "D6wBRhTEyRRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config.paths.use_local_paths()"
      ],
      "metadata": {
        "id": "-ZXGNSFJnXdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSIbvCxffUq4"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "import re\n",
        "import spacy\n",
        "import joblib\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def last_cat_helper_(df, flat_cats):\n",
        "  s = ''\n",
        "  truncated_cats=[]\n",
        "\n",
        "  for a in df.category:\n",
        "    if a not in flat_cats.index:\n",
        "      break\n",
        "    else:\n",
        "      truncated_cats.append(a)\n",
        "      s = a\n",
        "  return [s, truncated_cats]\n",
        "\n",
        "def extract_last_cat(df):\n",
        "  df.category = df.category.apply(lambda x:  ast.literal_eval(x))\n",
        "  flat_cats = pd.Series([cat for row in df['category'] for cat in row], name='a').value_counts()\n",
        "  flat_cats = flat_cats[flat_cats > 4]\n",
        "  last_cats = df.apply(last_cat_helper_, args=(flat_cats,), axis=1, result_type='expand')\n",
        "  df.loc[:, 'category'] = last_cats[1]\n",
        "  df.loc[:, 'cat'] = last_cats[0]\n",
        "  return df\n",
        "\n",
        "\n",
        "def cat_helper(row):\n",
        "  if row['cat'] in row['rank']:\n",
        "    row['rank'] = row['rank'].replace(\"'\", '\"')\n",
        "    current_rank = row['rank']\n",
        "    try:\n",
        "      rank_cats = json.loads(current_rank)\n",
        "    except Exception as e:\n",
        "      print(e, current_rank)\n",
        "\n",
        "    for a in rank_cats:\n",
        "      pattern = re.compile(\"'?>?#?([\\d,]+)\\s.*\"+re.escape(row['cat']))\n",
        "      m = pattern.search(a)\n",
        "      if m:\n",
        "        rank = int(m.group(1).replace(\",\", \"\"))\n",
        "        return rank\n",
        "  else:\n",
        "    return np.nan\n",
        "\n",
        "\n",
        "def extract_cat_rank(df):\n",
        "  #display(ddf[['rank', 'cat']].compute())\n",
        "  print(df.columns)\n",
        "  df[:, 'cat_rank'] = df.apply(cat_helper, axis=1)\n",
        "  return df\n",
        "\n",
        "def get_tokens(text) -> set:\n",
        "  text = html.unescape(text)\n",
        "  text = re.sub(r'[^a-zA-Z0-9 &]+', '', text)\n",
        "  doc = nlp(text)\n",
        "  tokens = set()\n",
        "  remove_set = set(['official', 'equipment', 'original', 'oem', \"heavy\", \"duty\", \"portable\", \"fast\", \"universal\", \"premium\", \"compact\"])\n",
        "\n",
        "  for a in doc:\n",
        "    if a.pos_ == \"NUM\" and a.head.pos_ in [\"PROPN\", \"NOUN\", \"ADP\"] and a.head.dep_ in ['ROOT', 'pobj', 'nmod', 'nsubj', 'conj']:\n",
        "      tokens.add(a.head.text + \" \" + a.text)\n",
        "      continue\n",
        "    elif a.dep_ in [\"compound\", \"pobj\", \"ROOT\", \"nmod\"]  and a.head.dep_ in [\"ROOT\", \"pobj\", \"nmod\", 'nsubj', 'compound', 'prep']:\n",
        "      tokens.add(a.lemma_.lower())\n",
        "\n",
        "  tokens = tokens - remove_set\n",
        "  return tokens\n",
        "\n",
        "rtokens = set()\n",
        "\n",
        "def apply_nlp_ner(row):\n",
        "  tokens = get_tokens(row)\n",
        "  for a in tokens:\n",
        "    rtokens.add(a)\n",
        "  return [*tokens]\n",
        "\n",
        "def extract_tags(df: pd.DataFrame) -> pd.DataFrame:\n",
        "  print(df)\n",
        "  # nlp = spacy.load('en_core_web_sm')\n",
        "  tags = df['title'].apply(apply_nlp_ner)\n",
        "  df['tags'] = tags\n",
        "  print(df, type(df))\n",
        "  # print('docs', docs)\n",
        "  return df\n",
        "\n",
        "\n",
        "def extract_title_tfidf(df: pd.DataFrame) -> dd.DataFrame:\n",
        "  vectorizer = TfidfVectorizer(max_features=32)\n",
        "  X = vectorizer.fit_transform(df['title'])\n",
        "  n = np.array([json.dumps(vec.tolist()) for vec in X.toarray()])\n",
        "  df['title_tfidf'] = n\n",
        "  df.drop(columns=['title'], inplace=True)\n",
        "  joblib.dump(vectorizer, config.paths.TFIDF_MODEL_PATH)\n",
        "  return df\n",
        "\n",
        "\n",
        "def build_item_features():\n",
        "  df = pd.read_parquet(config.paths.ITEMMETA_PARQUET_PATH)\n",
        "  df = extract_last_cat(df)\n",
        "  write_parquet('./1cats.parquet', df)\n",
        "  df = extract_tags(df)\n",
        "  write_parquet('./2tags.parquet', df)\n",
        "  df = extract_title_tfidf(df)\n",
        "\n",
        "  write_parquet(config.paths.ITEMMETA_PARQUET_PATH, df)\n",
        "\n",
        "\n",
        "build_item_features()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_parquet(config.paths.ITEMMETA_PARQUET_PATH, columns=['title'])\n",
        "df"
      ],
      "metadata": {
        "id": "f4HNgDlimyYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config.paths.use_local_paths()"
      ],
      "metadata": {
        "id": "0pxtBeObYM_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del df\n",
        "del config"
      ],
      "metadata": {
        "id": "B8muaZz2xjjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = Config()\n",
        "df = pd.read_parquet(config.paths.ITEMMETA_PARQUET_PATH, columns=[ 'category'])"
      ],
      "metadata": {
        "id": "Cu6y6Uwfu-Jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdA98PfaEAZc"
      },
      "source": [
        "## current"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9X0i2Xy7VY3q"
      },
      "outputs": [],
      "source": [
        "class Indexer:\n",
        "  data = {}\n",
        "  to_graph = {}\n",
        "  from_graph = {}\n",
        "  rel_types = {}\n",
        "  reverse_rel_types = {}\n",
        "  counter = 0\n",
        "  config: Config = None\n",
        "\n",
        "  def __init__(self, config):\n",
        "    self.counter = 0\n",
        "    self.config = config\n",
        "    pass\n",
        "\n",
        "  def persist(self):\n",
        "    pickler = IndexerPickler(self)\n",
        "    pickler.persist(self.config.paths.INDEXER_DATA_PATH)\n",
        "\n",
        "  @staticmethod\n",
        "  def load(config):\n",
        "    indexer = IndexerPickler.load(config.paths.INDEXER_DATA_PATH, config)\n",
        "    return indexer\n",
        "\n",
        "\n",
        "  def add_rel(self, id, reltype: str):\n",
        "    self.rel_types[reltype] = id\n",
        "    self.reverse_rel_types[id] = reltype\n",
        "\n",
        "\n",
        "  def add_node(self, local_id, rel_type):\n",
        "    self.to_graph[local_id] = self.counter\n",
        "    self.from_graph[self.counter] = local_id\n",
        "    if rel_type in self.data:\n",
        "      self.data[rel_type].add(self.counter)\n",
        "    else:\n",
        "      self.data[rel_type] = {self.counter}\n",
        "    self.counter += 1\n",
        "\n",
        "\n",
        "  def add_nodes(self, local_ids, rel_type):\n",
        "    for a in range(len(local_ids)):\n",
        "      self.to_graph[a] = self.counter\n",
        "      self.from_graph[self.counter] = a\n",
        "      if rel_type in self.data:\n",
        "        self.data[rel_type].add(self.counter)\n",
        "      else:\n",
        "        self.data[rel_type] = {self.counter}\n",
        "      self.counter += 1\n",
        "\n",
        "  def get_rel_type_single_(self, graph_id) -> str:\n",
        "    for key in self.data:\n",
        "      if graph_id in self.data[key]:\n",
        "        return key\n",
        "\n",
        "  def reltype_to_index(self, reltypes: list | str) -> list | int:\n",
        "    if isinstance(reltypes, str):\n",
        "      return self.rel_types[reltypes]\n",
        "    else:\n",
        "      index_list = []\n",
        "      for a in reltypes:\n",
        "        index_list.append(self.rel_types[a])\n",
        "      return index_list\n",
        "\n",
        "\n",
        "  def index_to_reltype(self, index: list | str) -> list | str:\n",
        "    if isinstance(index, int):\n",
        "      return self.reverse_rel_types[index]\n",
        "    else:\n",
        "      rel_list = []\n",
        "      for a in index:\n",
        "        rel_list.append(self.reverse_rel_types[a])\n",
        "      return rel_list\n",
        "\n",
        "\n",
        "  def rt(self, graph_ids) -> str | list:\n",
        "    if not isinstance(graph_ids, list):\n",
        "      return self.get_rel_type_single_(graph_ids)\n",
        "\n",
        "    rel_types = []\n",
        "    for a in graph_ids:\n",
        "      rel_types.append(self.get_rel_type_single_(a))\n",
        "    return rel_types\n",
        "\n",
        "\n",
        "  def gi(self, local_index):\n",
        "    '''Give the graph index providex the local index'''\n",
        "    if isinstance(local_index, list):\n",
        "      indexes = []\n",
        "      for a in local_index:\n",
        "        indexes.append(self.to_graph[a])\n",
        "      return indexes\n",
        "    return self.to_graph[local_index]\n",
        "\n",
        "  def li(self, graph_Index):\n",
        "    '''Give the local index prodvided graph index (or indexes)'''\n",
        "    if isinstance(graph_Index, list):\n",
        "      indexes = []\n",
        "      for a in graph_Index:\n",
        "        indexes.append(self.from_graph[a])\n",
        "      return indexes\n",
        "    return self.from_graph[graph_Index]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUk8Uqemnega"
      },
      "outputs": [],
      "source": [
        "class IndexerPickler:\n",
        "  data = {}\n",
        "  to_graph = {}\n",
        "  from_graph = {}\n",
        "  rel_types = {}\n",
        "  reverse_rel_types = {}\n",
        "  counter = 0\n",
        "\n",
        "  def __init__(self, index:Indexer):\n",
        "    self.counter =  index.counter\n",
        "    self.data =  index.data\n",
        "    self.to_graph =  index.to_graph\n",
        "    self.from_graph =  index.from_graph\n",
        "    self.rel_types =  index.rel_types\n",
        "    self.reverse_rel_types =  index.reverse_rel_types\n",
        "    self.counter = index.counter\n",
        "\n",
        "  def persist(self, path):\n",
        "    with open(path, 'wb') as f:\n",
        "      pickle.dump(self, f)\n",
        "\n",
        "  @staticmethod\n",
        "  def load(path, config):\n",
        "    indexer = None\n",
        "    with open(path, 'rb') as f:\n",
        "      ctx = pickle.load(f)\n",
        "      indexer = Indexer(config)\n",
        "      indexer.counter = ctx.counter\n",
        "      indexer.data = ctx.data\n",
        "      indexer.to_graph = ctx.to_graph\n",
        "      indexer.from_graph = ctx.from_graph\n",
        "      indexer.rel_types = ctx.rel_types\n",
        "      indexer.reverse_rel_types = ctx.reverse_rel_types\n",
        "      return indexer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRaHCgmUClcV"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbdwBLkedKvu"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import ast\n",
        "\n",
        "def safe_jsonload(string:str):\n",
        "  '''For debugging some items are not parsed and exception thrown.'''\n",
        "  try:\n",
        "    item = json.loads(string)\n",
        "    return item\n",
        "  except json.JSONDecodeError as e:\n",
        "    print('Decoding ', string, 'caused : ', e)\n",
        "    count, idx = 0, 0\n",
        "    for i in range(len(temp)):\n",
        "      if temp[i] == '\"':\n",
        "        count += 1\n",
        "      if count == 4:\n",
        "        idx = i\n",
        "        break\n",
        "    return json.loads(temp[:idx+1]+ ']')\n",
        "\n",
        "def extract_categories(items):\n",
        "  categories = []\n",
        "  pattern = re.compile(r'^[a-zA-Z &]+$')\n",
        "\n",
        "  for item in items:\n",
        "    words = item.split()\n",
        "    # Rule 1: Most words are capitalized\n",
        "    if sum(word[0].isupper() for word in words) / len(words) > 0.7:\n",
        "      # Rule 2: Length should be reasonable for a category (2-5 words)\n",
        "      if 1 <= len(words) <= 5:\n",
        "        if pattern.match(item):\n",
        "          categories.append(item)\n",
        "  return categories\n",
        "\n",
        "class DataTransformer:\n",
        "  review_df = None\n",
        "  meta_df = None\n",
        "  data = {}\n",
        "\n",
        "  def __init__(self, config: Config, indexer: Indexer):\n",
        "    self.config = config\n",
        "    self.indexer = indexer;\n",
        "    relation_types = [\n",
        "      'purchase',\n",
        "      'catcat',  # category hierarchial relations\n",
        "      'catuser', # user-category\n",
        "      'catitem', # item-category\n",
        "      'tag', # item-tag\n",
        "      'brand' # item-brand\n",
        "    ]\n",
        "    relations_df = pd.DataFrame({'id': np.arange(1, len(relation_types)+1) ,\"rel\": relation_types})\n",
        "    write_parquet(config.paths.RELATIONS_MAP_PATH, relations_df)\n",
        "\n",
        "\n",
        "  def load_relations(self):\n",
        "    rel_df = self.get_parquet_data(self.config.paths.RELATIONS_MAP_PATH)\n",
        "    for idx, row in rel_df.iterrows():\n",
        "      self.indexer.add_rel(row['id'], row['rel'])\n",
        "\n",
        "\n",
        "  def delete_review_data(self):\n",
        "    del self.review_df\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "  def delete_meta_data(self):\n",
        "    del self.meta_df\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "  def get_review_data(self) -> pd.DataFrame:\n",
        "    if self.review_df:\n",
        "      return self.review_df\n",
        "    else:\n",
        "      self.review_df = dd.read_parquet(self.config.paths.REVIEW_PARQUET_PATH).compute()\n",
        "      return self.review_df\n",
        "\n",
        "  def get_meta_data(self) -> pd.DataFrame:\n",
        "    if self.meta_df:\n",
        "      return self.meta_df\n",
        "    else:\n",
        "      self.meta_df = dd.read_parquet(self.config.paths.ITEMMETA_PARQUET_PATH).compute()\n",
        "      return self.meta_df\n",
        "\n",
        "\n",
        "  def get_parquet_data(self, path) -> pd.DataFrame:\n",
        "    if path in self.data:\n",
        "      return self.data[path]\n",
        "    else:\n",
        "      self.data[path] = dd.read_parquet(path).compute()\n",
        "      return self.data[path]\n",
        "\n",
        "\n",
        "  def extract_map(self, df, mappingCol, outputParquetPath, renameCol=None):\n",
        "    print(mappingCol)\n",
        "    map_df = df[[mappingCol]].drop_duplicates(ignore_index=True)\n",
        "    map_df['id'] = np.arange(len(map_df))\n",
        "    map_df = map_df[['id', mappingCol]]\n",
        "    if renameCol:\n",
        "      map_df = map_df.rename(columns=dict((mappingCol, renameCol)))\n",
        "    write_parquet(outputParquetPath, map_df)\n",
        "    self.indexer.add_nodes(map_df['id'], mappingCol)\n",
        "    return map_df\n",
        "\n",
        "\n",
        "  def assign_unique_ids_util_(self, df, col, uniqueDf):\n",
        "    df[col] = pd.merge(df, uniqueDf, on=col, how='left').id\n",
        "\n",
        "\n",
        "  def build_category_heirarchies(self, categories: pd.Series, uniqueCats: pd.DataFrame):\n",
        "    cat_heirarchies = set()\n",
        "    for cats in categories:\n",
        "      if cats is not None and len(cats) > 0:\n",
        "        for i in range(len(cats)-1):\n",
        "          a1 = uniqueCats[uniqueCats['cat'] == cats[i]].iloc[0].id\n",
        "          #a2 = uniqueCats[uniqueCats['cat'] == cats[i+1]].iloc[0].id\n",
        "          temp = uniqueCats[uniqueCats['cat'] == cats[i+1]]\n",
        "          if temp.empty:\n",
        "            print('cat is ', cats[i+1])\n",
        "            raise Exception()\n",
        "          else:\n",
        "            a2 = temp.iloc[0].id\n",
        "            cat_heirarchies.add((a1, a2))\n",
        "\n",
        "    subjects = [item[0] for item in cat_heirarchies]\n",
        "    objects  = [item[1] for item in cat_heirarchies]\n",
        "    heirarchy_ds = pd.DataFrame(data={\"parent\": subjects, \"child\": objects})\n",
        "    write_parquet(self.config.paths.CATEGORY_HIERARCHY_PATH, heirarchy_ds)\n",
        "    return heirarchy_ds\n",
        "\n",
        "\n",
        "  def build_mappings(self):\n",
        "    meta_df = self.get_meta_data()\n",
        "\n",
        "    unique_asins = self.extract_map(meta_df, 'asin', self.config.paths.ITEMID_MAP_PATH)\n",
        "    self.assign_unique_ids_util_(meta_df, 'asin', unique_asins)\n",
        "\n",
        "    review_df = self.get_review_data()\n",
        "\n",
        "    review_df = review_df.rename(columns={'reviewerID': 'uid'})\n",
        "    self.assign_unique_ids_util_(review_df, 'asin', unique_asins)\n",
        "\n",
        "    unique_reviewers = self.extract_map(review_df, 'uid', self.config.paths.UID_MAP_PATH)\n",
        "    self.assign_unique_ids_util_(review_df, 'uid', unique_reviewers)\n",
        "\n",
        "    unique_brands = self.extract_map(meta_df, 'brand', self.config.paths.BRANDS_MAPPING_PATH)\n",
        "    self.assign_unique_ids_util_(meta_df, 'brand', unique_brands)\n",
        "\n",
        "    #rating normalization\n",
        "    rating_encoder = MinMaxScaler()\n",
        "    review_df['rating'] = rating_encoder.fit_transform(review_df[['overall']])\n",
        "\n",
        "    # category mapping and heirarchy building\n",
        "    meta_df['category'] = meta_df['category'].apply(lambda x: extract_categories(x))\n",
        "    print(meta_df['category'])\n",
        "    # temp3 = pd.Series([cat for row in temp2 for cat in row], name='a').value_counts()\n",
        "    # temp3 = temp3[temp3 > 4]\n",
        "    flat_list = pd.Series([cat for row in meta_df['category'] for cat in row]).value_counts()\n",
        "    unique_cats = set(flat_list.index.tolist())\n",
        "    mapping_cat_df = pd.DataFrame(data={'id': np.arange(len(unique_cats)), 'cat': [*unique_cats]})\n",
        "    print(unique_cats)\n",
        "    self.build_category_heirarchies(meta_df['category'], mapping_cat_df)\n",
        "    self.assign_unique_ids_util_(meta_df, 'cat', mapping_cat_df)\n",
        "    self.indexer.add_nodes(mapping_cat_df['id'], 'cat')\n",
        "    meta_df.fillna(mapping_cat_df.loc[mapping_cat_df['cat'] == flat_list.index[0]].iloc[0].id, inplace=True)\n",
        "\n",
        "    # Tag mapping\n",
        "    tag_flat_list = [tag for row in meta_df['tags'] for tag in row]\n",
        "    unique_tags = set(tag_flat_list)\n",
        "    mapping_tag_df = pd.DataFrame(data={'id': np.arange(len(unique_tags)), 'tag': [*unique_tags]})\n",
        "    self.indexer.add_nodes(mapping_tag_df['id'], 'tag')\n",
        "\n",
        "    meta_df.drop(columns=['price', 'category', 'also_buy', 'rank', 'feature'], inplace=True)\n",
        "\n",
        "    write_parquet(self.config.paths.TAGS_MAPPING_PATH, mapping_tag_df)\n",
        "    write_parquet(self.config.paths.CATEGORY_MAPPING_PATH, mapping_cat_df)\n",
        "    write_parquet(self.config.paths.ITEM_EMBEDDIGNS_PATH, meta_df)\n",
        "    write_parquet(self.config.paths.USER_EMBEDDINGS_PATH, review_df)\n",
        "\n",
        "    self.indexer.persist()\n",
        "\n",
        "\n",
        "  def build_triples(self):\n",
        "    itememb = self.get_parquet_data(self.config.paths.ITEM_EMBEDDIGNS_PATH)\n",
        "\n",
        "    brand_triples = itememb[['asin', 'brand']]\n",
        "    write_parquet(self.config.paths.TRIPLES_BRANDS_PATH, brand_triples)\n",
        "\n",
        "    itemcat_triples = itememb[['asin', 'cat']]\n",
        "    write_parquet(self.config.paths.TRIPLES_ITEMCAT_PATH, itemcat_triples)\n",
        "\n",
        "    tags = itememb[['asin', 'tags']].explode('tags', ignore_index=True)\n",
        "    tagsmapping = self.get_parquet_data(self.config.paths.TAGS_MAPPING_PATH)\n",
        "    tag_groups = tagsmapping.groupby('tag')['id'].first()\n",
        "    tags['tags'] = [tag_groups.get(tag) for tag in tags['tags']]\n",
        "    write_parquet(self.config.paths.TRIPLES_TAGS_PATH, tags)\n",
        "\n",
        "  def build_embeddings(self):\n",
        "    # Item embeddings\n",
        "    itememb = self.get_parquet_data(self.config.paths.ITEM_EMBEDDIGNS_PATH)\n",
        "    itememb = itememb.join(itememb['title_tfidf']\n",
        "                 .apply(lambda x: json.loads(x))\n",
        "                 .apply(pd.Series).rename(columns= lambda x: 'tf_' + str(x)))\n",
        "    # cat_rank was removed. reminder: add it back if added above.\n",
        "    itememb = itememb.drop(columns=['brand', 'cat', 'tags', 'title_tfidf'])\n",
        "    write_parquet(self.config.paths.ITEM_EMBEDDIGNS_PATH, itememb)\n",
        "\n",
        "    # Purchase relation embeddings\n",
        "    purchase_emb = self.get_parquet_data(self.config.paths.USER_EMBEDDINGS_PATH)\n",
        "    purchase_emb = purchase_emb.drop(columns=['overall'])\n",
        "    write_parquet(self.config.paths.USER_EMBEDDINGS_PATH, purchase_emb)\n",
        "\n",
        "  def clear_parquets(self):\n",
        "    '''Warning: for manual calling only. will delete parquets. util'''\n",
        "    review_df = None\n",
        "    meta_df = None\n",
        "    data = {}\n",
        "    !rm ./brands_map.parquet\n",
        "    !rm itemid_map.parquet\n",
        "    !rm relations_map.parquet\n",
        "    !rm uid_map.parquet\n",
        "    !rm category_hierarchy.parquet\n",
        "    !rm category_map.parquet\n",
        "    !rm indexer_path.pickle\n",
        "    !rm itemembeddings.parquet\n",
        "    !rm tags_map.parquet\n",
        "    !rm triples_itemcat.parquet\n",
        "    !rm triples_brands.parquet\n",
        "    !rm triples_tags.parquet\n",
        "    !rm userembeddings.parquet\n",
        "    !rm triples*.parquet\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "  def transform(self):\n",
        "    self.load_relations()\n",
        "    self.build_mappings()\n",
        "    self.build_triples()\n",
        "    self.build_embeddings()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T10l8tpVpucg"
      },
      "outputs": [],
      "source": [
        "# if config != None:\n",
        "#   del config\n",
        "# if g_indexer != None:\n",
        "#   del g_indexer\n",
        "# if transformer != None:\n",
        "#   del transformer\n",
        "config = Config()\n",
        "config.paths.use_local_paths()\n",
        "g_indexer = Indexer(config)\n",
        "transformer = DataTransformer(config, g_indexer)\n",
        "transformer.transform()\n",
        "# transformer.clear_parquets()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp {config.paths.DRIVE_DATASET_PATH}/parquets/review.parquet ./review.parquet"
      ],
      "metadata": {
        "id": "FBFUwdKSriFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_parquet(config.paths.ITEMMETA_PARQUET_PATH, columns=['category', 'cat'])\n",
        "temp = df.cat.value_counts()"
      ],
      "metadata": {
        "id": "eOTZkcQ326Gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la *.parquet"
      ],
      "metadata": {
        "id": "NHxqMIZN3CzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIcBrv-Wgzjs"
      },
      "outputs": [],
      "source": [
        "config.paths.copy_to_drive()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp ./2tags.parquet ./data/MyDrive/"
      ],
      "metadata": {
        "id": "z4VmNOu4zDfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbAtuIcrTxWn"
      },
      "source": [
        "## Fn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gbl50FowXcZI"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8tqDpnd6z_c"
      },
      "source": [
        "## Recommendation Graph Construction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U12i2KYFmfzU"
      },
      "outputs": [],
      "source": [
        "import networkx as nx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRULcZG9mQkK"
      },
      "outputs": [],
      "source": [
        "knowledge_graph = nx.Graph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlzWU51CmX3C"
      },
      "source": [
        "####  Add user-item interactions edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTswa6Fmmxlq"
      },
      "outputs": [],
      "source": [
        "for idx, row in review_data.iterrows():\n",
        "  knowledge_graph.add_edge(f\"u_{row['reviewerID_encoded']}\", f\"i_{row['asin_encoded']}\",\n",
        "               type='interacts', weight=row['helpful_votes'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V85mhMe6uNDT"
      },
      "source": [
        "## GNN implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0exeAQxjx86l"
      },
      "outputs": [],
      "source": [
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYB6Lx0KyTkP"
      },
      "outputs": [],
      "source": [
        "import torch as t\n",
        "import torch.nn as nn\n",
        "import torch_geometric.nn as pyg_nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhij1zOxxgFj"
      },
      "outputs": [],
      "source": [
        "class GNNModel(nn.Module):\n",
        "    def __init__(self, num_users, num_items, emb_dim):\n",
        "        super(GNNModel, self).__init__()\n",
        "        self.embedding_dim = emb_dim\n",
        "\n",
        "        self.user_embeddings = nn.Embedding(num_users, emb_dim)\n",
        "        self.item_embeddings = nn.Embedding(num_items, emb_dim)\n",
        "\n",
        "        self.conv1 = pyg_nn.GCNConv(emb_dim, emb_dim)\n",
        "        self.conv2 = pyg_nn.GCNConv(emb_dim, emb_dim)\n",
        "\n",
        "    def forward(self, data):\n",
        "\n",
        "        x = t.cat([self.user_embeddings.weight, self.item_embeddings.weight], dim=0)\n",
        "\n",
        "        # GCN Layer 1\n",
        "        x = self.conv1(x, data.edge_index, edge_attr=data.edge_attr)\n",
        "        x = t.relu(x)\n",
        "\n",
        "        # GCN Layer 2\n",
        "        x = self.conv2(x, data.edge_index, edge_attr=data.edge_attr)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnGdvzayzvm9"
      },
      "outputs": [],
      "source": [
        "class DotPredictor(pyg_nn.MessagePassing):\n",
        "    def forward(self, data, h):\n",
        "        x = data.x\n",
        "        edge_index = data.edge_index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4HoVf3pjxYB"
      },
      "outputs": [],
      "source": [
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bc-dmaBiKFR"
      },
      "outputs": [],
      "source": [
        "with open(m) as f:\n",
        "  for i in range(1000):\n",
        "    val = f.readline()\n",
        "    obj = json.loads(val)\n",
        "    features = obj['rank']\n",
        "    a2 = obj['category']\n",
        "    #for feature in features:\n",
        "    if features:\n",
        "      print('[', features,',', a2, ']')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIHZ3gKCiLkw"
      },
      "outputs": [],
      "source": [
        "s = [ ['>#6,681,833 in Cell Phones & Accessories (See top 100)', '>#286,289 in Cell Phones & Accessories > Cell Phone Accessories > Accessory Kits', '>#6,677,630 in Electronics > Cell Phones & Accessories'] , ['Cell Phones & Accessories', 'Accessories', 'Accessory Kits'] ]\n",
        "\n",
        "for a in s:\n",
        "  for b in a:\n",
        "    print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YV_iJ9cIJNE"
      },
      "outputs": [],
      "source": [
        "jsons = []\n",
        "\n",
        "with open(m, 'r') as f:\n",
        "  for a in range(500):\n",
        "    if a < 200:\n",
        "      continue\n",
        "    jsons.append(f.readline())\n",
        "\n",
        "df = pd.read_json('\\n'.join(jsons), lines=True)\n",
        "df.to_csv('cellphones_meta.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LfZDfU1U3_t"
      },
      "outputs": [],
      "source": [
        "def get_pd(file, take, skip):\n",
        "  jsons = []\n",
        "\n",
        "  with open(file, 'r') as f:\n",
        "    for a in range(take):\n",
        "      if a < skip:\n",
        "        continue\n",
        "      jsons.append(f.readline())\n",
        "\n",
        "  df = pd.read_json('\\n'.join(jsons), lines=True)\n",
        "  df.to_csv(file + '.csv')\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Nsn9gk2VJpe"
      },
      "outputs": [],
      "source": [
        "def download_to_csv(url, jsonName, skip, take):\n",
        "  if not os.path.exists(jsonName):\n",
        "    saved_result = urllib.request.urlretrieve(url, jsonName)\n",
        "    print(saved_result)\n",
        "    extract_gz(saved_result[0], jsonName)\n",
        "\n",
        "  jsons = []\n",
        "\n",
        "  with open(jsonName, 'r') as f:\n",
        "    for a in range(take):\n",
        "      if a < skip:\n",
        "        continue\n",
        "      jsons.append(f.readline())\n",
        "\n",
        "  df = pd.read_json('\\n'.join(jsons), lines=True)\n",
        "  df.to_csv(jsonName + '.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASJQbQxvgPJX"
      },
      "outputs": [],
      "source": [
        "download_to_csv('https://jmcauley.ucsd.edu/data/amazon_v2/categoryFilesSmall/Tools_and_Home_Improvement_5.json.gz',\n",
        "                'movies.json',\n",
        "                200,\n",
        "                500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGw0PVtvhJUl"
      },
      "outputs": [],
      "source": [
        "!head movies.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxZ9qh6Tn50O"
      },
      "outputs": [],
      "source": [
        "!curl -k -o office_products.json.gz https://mcauleylab.ucsd.edu/public_datasets/data/amazon_v2/metaFiles2/meta_Office_Products.json.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3wtYvfvocmO"
      },
      "outputs": [],
      "source": [
        "!gunzip -r ./office_products.json.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVntl01Vprmi"
      },
      "outputs": [],
      "source": [
        "df = pd.read_json('./afn', lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOsK2dH4p92X"
      },
      "outputs": [],
      "source": [
        "df[df['reviewerID'] == 'A3H9DSJS96YY84']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxHOrYewp_bO"
      },
      "outputs": [],
      "source": [
        "get_pd('office_products.json', 500, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHzih9LHNnOR"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('./office_products.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wonrvKMGmEwb"
      },
      "outputs": [],
      "source": [
        "features = df.tech1\n",
        "\n",
        "for a in range(10):\n",
        "  print(features[a])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKsddcWjOKbA"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "import itertools\n",
        "\n",
        "strs = set()\n",
        "\n",
        "for feature_str in features:\n",
        "  try:\n",
        "    feature = ast.literal_eval(feature_str)\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    break\n",
        "  if feature and len(feature) > 0:\n",
        "    for a in feature:\n",
        "      strs.add(a)\n",
        "for a in strs:\n",
        "  print(a)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}