{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca4e0941-0e54-4f4b-a507-daed2bc706b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f090bf1a-06be-4c35-8209-141023695d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.]], dtype=torch.float64),\n",
       " tensor([[ 6.],\n",
       "         [10.],\n",
       "         [14.],\n",
       "         [18.],\n",
       "         [22.]], dtype=torch.float64))"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[x] for x in range(1,6)], dtype=float)\n",
    "Y = 4 * X + 2\n",
    "X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "dd5f76ae-b113-4bce-8ee9-d54fd123d6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modal(nn.Linear):\n",
    "    def init(self):\n",
    "        self.__init__(2,2)\n",
    "        print('init')\n",
    "    def forward(self):\n",
    "        print('forward')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "be49453a-fcc2-45ed-97e2-e1c9d585e1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(0, requires_grad=True, dtype=torch.float)\n",
    "a = torch.tensor(0, requires_grad=True, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b94b9e3c-cebc-44ea-9354-1a7f11e9bc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(Y_hat, Y):\n",
    "    return (Y_hat - Y).pow(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "71ef1c5a-a7f7-40c7-83ed-b1503b8dc368",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[202], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(linear\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m250\u001b[39m):\n\u001b[1;32m----> 5\u001b[0m     Y_hat \u001b[38;5;241m=\u001b[39m linear(\u001b[43mX\u001b[49m)\n\u001b[0;32m      6\u001b[0m     diff \u001b[38;5;241m=\u001b[39m loss(Y_hat, Y)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiff\u001b[39m\u001b[38;5;124m'\u001b[39m, diff)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "linear = nn.Linear(1,1,dtype=torch.float64)\n",
    "optimizer = torch.optim.Adam(linear.parameters(), lr=100)\n",
    "\n",
    "for i in range(250):\n",
    "    Y_hat = linear(X)\n",
    "    diff = loss(Y_hat, Y)\n",
    "    print('diff', diff)\n",
    "    diff.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    print(*linear.parameters(), Y_hat)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c612753e-e2e1-4c1c-bdd5-0f8463aeed7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mX\u001b[49m,Y\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fef7812-a988-4384-a406-7a822a818370",
   "metadata": {},
   "source": [
    "# Checking different optimizors\n",
    "\n",
    "We are finding different equation roots using AutoGrad and various optimizors. Use the graphs to visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "2dae06db-9751-4c82-ac76-17966cf797a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12., requires_grad=True)"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(12, dtype=torch.float32 , requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "e41a5b0e-6dd1-47c0-be47-6df200344629",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.tensor(0, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "c4591277-4ee6-4447-8732-1302774e3466",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizor = torch.optim.Adam([x], lr=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "24da4dcd-c6b0-4806-abb4-07344b8137c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "fb916792-f5e5-4c5d-92e0-fe7b606418fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(25.6682, grad_fn=<AddBackward0>) , tensor(3.4725, requires_grad=True) tensor(0.)\n",
      "tensor(25.1132, grad_fn=<AddBackward0>) , tensor(3.3655, requires_grad=True) tensor(0.)\n",
      "tensor(24.5958, grad_fn=<AddBackward0>) , tensor(3.2615, requires_grad=True) tensor(0.)\n",
      "tensor(24.1142, grad_fn=<AddBackward0>) , tensor(3.1602, requires_grad=True) tensor(0.)\n",
      "tensor(23.6666, grad_fn=<AddBackward0>) , tensor(3.0619, requires_grad=True) tensor(0.)\n",
      "tensor(23.2512, grad_fn=<AddBackward0>) , tensor(2.9663, requires_grad=True) tensor(0.)\n",
      "tensor(22.8663, grad_fn=<AddBackward0>) , tensor(2.8736, requires_grad=True) tensor(0.)\n",
      "tensor(22.5102, grad_fn=<AddBackward0>) , tensor(2.7836, requires_grad=True) tensor(0.)\n",
      "tensor(22.1813, grad_fn=<AddBackward0>) , tensor(2.6965, requires_grad=True) tensor(0.)\n",
      "tensor(21.8779, grad_fn=<AddBackward0>) , tensor(2.6120, requires_grad=True) tensor(0.)\n",
      "tensor(21.5987, grad_fn=<AddBackward0>) , tensor(2.5304, requires_grad=True) tensor(0.)\n",
      "tensor(21.3420, grad_fn=<AddBackward0>) , tensor(2.4514, requires_grad=True) tensor(0.)\n",
      "tensor(21.1065, grad_fn=<AddBackward0>) , tensor(2.3751, requires_grad=True) tensor(0.)\n",
      "tensor(20.8908, grad_fn=<AddBackward0>) , tensor(2.3014, requires_grad=True) tensor(0.)\n",
      "tensor(20.6936, grad_fn=<AddBackward0>) , tensor(2.2303, requires_grad=True) tensor(0.)\n",
      "tensor(20.5137, grad_fn=<AddBackward0>) , tensor(2.1618, requires_grad=True) tensor(0.)\n",
      "tensor(20.3499, grad_fn=<AddBackward0>) , tensor(2.0959, requires_grad=True) tensor(0.)\n",
      "tensor(20.2010, grad_fn=<AddBackward0>) , tensor(2.0324, requires_grad=True) tensor(0.)\n",
      "tensor(20.0659, grad_fn=<AddBackward0>) , tensor(1.9714, requires_grad=True) tensor(0.)\n",
      "tensor(19.9436, grad_fn=<AddBackward0>) , tensor(1.9128, requires_grad=True) tensor(0.)\n",
      "tensor(19.8332, grad_fn=<AddBackward0>) , tensor(1.8566, requires_grad=True) tensor(0.)\n",
      "tensor(19.7337, grad_fn=<AddBackward0>) , tensor(1.8026, requires_grad=True) tensor(0.)\n",
      "tensor(19.6442, grad_fn=<AddBackward0>) , tensor(1.7510, requires_grad=True) tensor(0.)\n",
      "tensor(19.5640, grad_fn=<AddBackward0>) , tensor(1.7015, requires_grad=True) tensor(0.)\n",
      "tensor(19.4921, grad_fn=<AddBackward0>) , tensor(1.6543, requires_grad=True) tensor(0.)\n",
      "tensor(19.4281, grad_fn=<AddBackward0>) , tensor(1.6091, requires_grad=True) tensor(0.)\n",
      "tensor(19.3710, grad_fn=<AddBackward0>) , tensor(1.5661, requires_grad=True) tensor(0.)\n",
      "tensor(19.3204, grad_fn=<AddBackward0>) , tensor(1.5250, requires_grad=True) tensor(0.)\n",
      "tensor(19.2756, grad_fn=<AddBackward0>) , tensor(1.4859, requires_grad=True) tensor(0.)\n",
      "tensor(19.2361, grad_fn=<AddBackward0>) , tensor(1.4488, requires_grad=True) tensor(0.)\n",
      "tensor(19.2014, grad_fn=<AddBackward0>) , tensor(1.4135, requires_grad=True) tensor(0.)\n",
      "tensor(19.1709, grad_fn=<AddBackward0>) , tensor(1.3800, requires_grad=True) tensor(0.)\n",
      "tensor(19.1444, grad_fn=<AddBackward0>) , tensor(1.3482, requires_grad=True) tensor(0.)\n",
      "tensor(19.1213, grad_fn=<AddBackward0>) , tensor(1.3182, requires_grad=True) tensor(0.)\n",
      "tensor(19.1012, grad_fn=<AddBackward0>) , tensor(1.2898, requires_grad=True) tensor(0.)\n",
      "tensor(19.0840, grad_fn=<AddBackward0>) , tensor(1.2630, requires_grad=True) tensor(0.)\n",
      "tensor(19.0691, grad_fn=<AddBackward0>) , tensor(1.2377, requires_grad=True) tensor(0.)\n",
      "tensor(19.0565, grad_fn=<AddBackward0>) , tensor(1.2139, requires_grad=True) tensor(0.)\n",
      "tensor(19.0458, grad_fn=<AddBackward0>) , tensor(1.1915, requires_grad=True) tensor(0.)\n",
      "tensor(19.0367, grad_fn=<AddBackward0>) , tensor(1.1706, requires_grad=True) tensor(0.)\n",
      "tensor(19.0291, grad_fn=<AddBackward0>) , tensor(1.1509, requires_grad=True) tensor(0.)\n",
      "tensor(19.0228, grad_fn=<AddBackward0>) , tensor(1.1325, requires_grad=True) tensor(0.)\n",
      "tensor(19.0176, grad_fn=<AddBackward0>) , tensor(1.1154, requires_grad=True) tensor(0.)\n",
      "tensor(19.0133, grad_fn=<AddBackward0>) , tensor(1.0994, requires_grad=True) tensor(0.)\n",
      "tensor(19.0099, grad_fn=<AddBackward0>) , tensor(1.0845, requires_grad=True) tensor(0.)\n",
      "tensor(19.0071, grad_fn=<AddBackward0>) , tensor(1.0708, requires_grad=True) tensor(0.)\n",
      "tensor(19.0050, grad_fn=<AddBackward0>) , tensor(1.0580, requires_grad=True) tensor(0.)\n",
      "tensor(19.0034, grad_fn=<AddBackward0>) , tensor(1.0462, requires_grad=True) tensor(0.)\n",
      "tensor(19.0021, grad_fn=<AddBackward0>) , tensor(1.0354, requires_grad=True) tensor(0.)\n",
      "tensor(19.0013, grad_fn=<AddBackward0>) , tensor(1.0254, requires_grad=True) tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    y = x**2 - 2*x + 20\n",
    "    y.backward()\n",
    "    optimizor.step()\n",
    "    print(y, ',', x, m)\n",
    "    l.append((x.item(),y.item()))\n",
    "    optimizor.zero_grad()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "455ae853-28b9-48aa-9355-54ebeaf7e559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "d9b4e611-dfad-468d-9ff8-e8ab2599192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "7c673b47-4960-4cad-ad47-fb4084c091e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = []\n",
    "y1 = []\n",
    "for a in l:\n",
    "    x1.append(a[0])\n",
    "    y1.append(a[1])\n",
    "plt.plot(x1,y1)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "33961ff8-268b-4fed-b262-d9f04c661eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.linspace(-20, 20, 200)\n",
    "t = r**2 - 2*r + 20\n",
    "plt.plot(r,t)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
